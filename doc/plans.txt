/* cmpr design ideas / plans

Files and blocks
----

20240409 Wed

Files can be empty, but blocks are never empty, which means an empty file contains no blocks.

We maintain the clean definition of blocks (they are non-empty spans of texts) and we also respect the idea of files.

Therefore, j/k order is a union of the file list and the block list.

We do away with the earlier idea of empty blocks only in empty files.

As an example, if the project contains files a, b, c, and d containing the following blocks:

a: 1 2 3
b: no blocks
c: 4 5
d: 6

In j/k order (formally, just kidding order) we visit three blocks for file a, and the empty file b, and then the fourth block in file c.

Unlike as of v5, we do not count a block index for the empty file b, which means you can add an empty file to your project to record the intention to store some blocks there in the future without changing the number of blocks in your project.
The language of empty files does not even need to be defined, at least not for ingest.
Files and blocks are separate lists, but they have a total order.

Now we also say (as of v6, say) that every block has a checksum.
The checksum isn't guaranteed to stay the same between versions, but the tool should be responsible for updating it, which means at least one overlap between checksum implementations to support version upgrading.
If the file is very short we may just store the content itself.

For now, we are assuming that the only use we have for the checksums is that we can identify whether a file contents have changed.
If they have, we can identify changes to individual blocks if the file is divided into blocks.
However, as the checksum function we are using is of course opaque, we will not be able to measure block similarity, only content-identity, and that only probabilistically.

The concept of empty files also makes vi-like normal mode commands like d, p, o, useful to do things like take a block from an existing file with d and move it into a new file with p, even if that file was empty.
Obviously this will get more useful when we have actual content-aware hashing.








Basic operations
----
20240310

The basic operations are all on blocks.

They are:

r/R (currently split into two parts but logically one operation)
d (not implemented)
o (not implemented)
e
x (not implemented)
p/P (not implemented)

These are all modifying operations, but we also have:

undo
redo
diff

This family of operations change the block contents, but not necessarily to something new.
Undo is "u" in vim, but redo requires a modifier key.
I'm not sure if we want to keep these exact keyboard shortcuts, especially as modifier keys are difficult in some environments (e.g. browsers).

We also need new keys for the inverse operations of "r/R".
This really needs, to be full-featured, to include getting the full block into the clipboard, getting the comment part or code part, and optionally applying some transformation to either one of these.

An easy DSL to express this is the following:

prompt("writethecode",commentpart(block))

In this idea, block is a local variable, commentpart and prompt are functions, and the string literal "writethecode" is an identifier for a prompt template which in this case takes a single argument.

Arguments to prompts are always positional and can always be empty.
The prompt "writethecode" might be given on the conf file or could come from a block of prompt templates, or another conf file, e.g. a "writethecode" file in a .cmpr/prompts/ directory or similar.









Implementation plan
----
20240310

When we read in data from disk (in get_code) we should also do all indexing operations.

This means we get checksums for all our blocks and all lines.

In particular:

- we make a lines spans which we store on ui_state
- this will be kept up to date for data that is in memory only

It is intended that the backing file always contains the same lines as we have in inp.

However, as we do not exclusively own the file, we always check it when opening a project and again before writing.

Specifically, when we write, we first copy the file, if it exists, to a .bak copy.
We read the bytes of this file and compare them with what we have in memory.
Note that in new_rev we still have the previous contents of the file (since that is where we update file.contents and inp and therefore the block contents as well).




























Networking Plan
----

A revstore:

- stores blocks
- serves lists of block hashes which it has
- serves block contents for a given hash when asked
- only allows known users to write to it
- may have access controls on who can read from it
- (necessarily) has rate limits on all access for all users

Because a revstore is controlled by a certain author, it's a great place to get vetted news, if you trust that author (or curator).

Guiding principle:

Whenever possible, determine everything from the revstore contents itself.

> cmpr --rvs-server

























Outputs
----

Let's say the filetype is HTML.
It would be natural to be able to view the output (maybe continuously updated) without having to use the (B)uild command just for that.
So let's say we have "V" or :view for view, and this could include a 20px fixed header with a history bar.
The current contents will automatically refresh.

However, we might not want to treat an HTML file (particularly a generated one) as a source of blocks.
This means if we have Library: we should have View: as well.
The point is to bring the view into the workflow (for example, as an input to some procedure) but not add blocks.
Note that you can still edit a file.
The necessity for View: to open an external browser is a limitation of the terminal interface.
In particular, it will not play nicely with SSH.
A :view-url would be a nice way to get a network-friendly https url to fetch HTML from.

































Block chains
----

As a simple example of a more general idea, we propose chains of blocks as an include mechanism.

As an LLM requires input to be provided in some order, each block can strictly speaking only have one block immediately preceding it.

The idea of a block chain is just this: each block may name its immediate predecessor.

The syntax for this can be as follows:

<block-start-token> #name-of-block @predecessor-name

This suggests two basic features:

1. An index of block names to block indices.

2. A transform on blocks that expands references (transitively) and removes references if desired.

The implementation is like this:

expand_blockrefs: Block -> State BlockChain
expand_blockrefs Complete b := b
expand_blockrefs Child b := expand_blockrefs (expand_parent b)

Where expand_parent simply concatenates the parent block to the block itself.
Obviously, expand_blockrefs can be extended to have multiway branching, to intelligently handle cycles, and so on.

This can be seen as a specific case of a more general pattern:

1. look up a block
2. do something with it

In the case of r/R this is split the comment part, wrap it with a prompt template, send it to an LLM, and replace the remaining suffix of the block with the LLM output.
There's a human in the loop, which is enhanced if we have both "r" (regenerate) and "u" (undo) in the same UI.

The idea for "r" implementation is that if you turn the API on, it just does it.
Then you have "u" to go back, and perhaps some kind of diff view.
I think "U" could be for the diff view features and an undo/redo list; like search mode it would be a new view.
It might show a scrollable list of all revs of the current block.
It would show commands on the ruler, such as space to select/mark a rev, d to see diffs between marked and current, perhaps m to do a three-way merge (you select three revs, it puts all the lines that were in any of them into the same file and you edit it), and so on.

An idea nearby the block parent sigil is one for block filters, each of which is just a function applied in order.
For example:

<block_start> #some_block .func1 .func2

Would produce func2(func1(block contents)).

























Name spaces
----

A name space is a list of pairs of checksums and names.
It is published by a revstore which also hosts blocks having all the given checksums.

There can only be one name for a block in a given namespace.

As an example, I can publish at spanio.cmpr.ai my own namespace for the spanio library.

I can also publish all of the blocks.

Then you can run any of my code by getting an index block from my server, listing the name space, searching the names, and accessing any of interest.
































Third half
----

The third half is the diff layer.

If you have a block and you want a better version of that block, you want to be able to describe the difference in English and have ChatGPT make it happen.

In other words, there are two dimensions:

- block index dimension
- time dimension

Between any two blocks a, b, there is a diff d(a,b) that represents the change from a to b, a delta or derivative.

A very natural operation is describe_diff(a, b) which is like diff(a, b) but it adds an English explanation.

This can be something like "This fixes a bug in the code by changing a pointer from an incorrect to a correct value" but a more useful description would include variable names and similar detail such that the patch can likely be recreated.

In common use with ChatGPT, the user may say "the code needs to be fixed to do ..." and the LLM replies with a suggested change.
This is going from an English diff to a diff in PL code.

The reverse operation is also interesting: given a change in PL code, find the corresponding change to the English (NL) code.

In fact, as there are both NL and PL texts and also NL and PL deltas, there are at least four interesting arrows: NL to PL is handled by the LLM (mainly), PL to NL is sometimes done when debugging or when ingesting code.
A NL delta may be taken as a change to NL or to PL, similarly a PL delta may be a PL change (e.g. a standard diff) or may be interpreted (by either human or LLM) as a change to NL.

We can also define different kinds of deltas.
For example, a unified diff is a textually unambiguous delta, but a description in English of a change is also a kind of delta.
The LLM or the human may convert between these.
In particular, conversion between English descriptions of changes to the code and unambiguous diffs to the original English description is how we go from an English conversation (ending in a complete program) to a single English program (resulting in a functionally identical PL program).

For any block we can define at least three significant kinds of neighbors.
First we have the parent block in time.
This is whatever it was before you edited it into its current state.

Second we have some block chain parent.
This is the pointer to the foundational information on which we depend.
(The root node by the way could be considered implicitly to point to GPT4 as currently we don't expect it to work on other models without testing.
This is a way of saying we depend on some knowledge built into the model.)
This is a temporal relationship loosely speaking, but can be edited easily, e.g. when a bootstrap block gets split into subcomponents.

Third is nearby blocks in some metric space, such as nearby programs.
An example would be our functions that split files into blocks, which are very similar to each other but with minor differences for each PL.

























Implementation plans
----
20240310

First we set up the indices: lines, blocks, files.

Then we review this file and work out a plan.

But before any of that, it turns out, we are actually implementing openai-key support.

We get the openai-key from a file .cmpr/openai-key which must be owned and readable only by the current user (i.e. chmod 0400).

The end library experience we want should be span result = llm(span).

We want to record all our API inputs and outputs.

Before calling llm() we will call some other setup functions.

So the API we want from the rest of the code is just this:

- setup_llm(): does whatever is required to be able to use the LLM
- llm(): uses the LLM
- free_llm(): does whatever cleanup is required

All the specifics of what the LLM is and what these steps are can change by configuration.

(Basically implemented this, but with the model name instead of llm() as the function name.
 I don't think supporting just one LLM at a time is good enough since you'll likely want different ones for different blocks or different commands.
 The argument to llm(), though not settled here, turned out to be a json array of messages, each with role and content, as in the OpenAI chat API.)
*/

